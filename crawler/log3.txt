2021-04-26 00:42:27 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: crawler)
2021-04-26 00:42:27 [scrapy.utils.log] INFO: Versions: lxml 4.6.3.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.2.0, Python 3.7.8 (tags/v3.7.8:4b47a5b6ba, Jun 28 2020, 08:53:46) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 20.0.1 (OpenSSL 1.1.1k  25 Mar 2021), cryptography 3.4.7, Platform Windows-10-10.0.19041-SP0
2021-04-26 00:42:27 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2021-04-26 00:42:27 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'crawler',
 'CONCURRENT_REQUESTS': 100,
 'DEPTH_PRIORITY': 1,
 'LOG_FILE': 'log3.txt',
 'NEWSPIDER_MODULE': 'crawler.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SCHEDULER_DISK_QUEUE': 'scrapy.squeues.PickleFifoDiskQueue',
 'SCHEDULER_MEMORY_QUEUE': 'scrapy.squeues.FifoMemoryQueue',
 'SPIDER_MODULES': ['crawler.spiders']}
2021-04-26 00:42:27 [scrapy.extensions.telnet] INFO: Telnet Password: 76d5d7111cd826eb
2021-04-26 00:42:27 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2021-04-26 00:42:27 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2021-04-26 00:42:27 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2021-04-26 00:42:27 [scrapy.middleware] INFO: Enabled item pipelines:
['crawler.pipelines.CrawlerPipeline']
2021-04-26 00:42:27 [scrapy.core.engine] INFO: Spider opened
2021-04-26 00:42:27 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2021-04-26 00:42:27 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2021-04-26 00:42:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://1004.1004cors.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: 1004.1004cors.com.
2021-04-26 00:42:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://1004hks.com> (referer: None)
2021-04-26 00:42:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://123-top3.top> (failed 1 times): DNS lookup failed: no results for hostname lookup: 123-top3.top.
2021-04-26 00:42:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://11.xn--he5b93brek8q.com> (referer: None)
2021-04-26 00:42:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://1004svs.com> (referer: None)
2021-04-26 00:42:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://1004x.1004tsts.com> (referer: None)
2021-04-26 00:42:28 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (meta refresh) to <GET https://zzolboo68.com/> from <GET http://22kbs.com>
2021-04-26 00:42:28 [scrapy.core.scraper] ERROR: Spider error processing <GET http://1004hks.com> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:42:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://1234.1004vvt.com> (referer: None)
2021-04-26 00:42:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://5rs-wc21.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: 5rs-wc21.com.
2021-04-26 00:42:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://77-tws.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: 77-tws.com.
2021-04-26 00:42:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://assktv9.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: assktv9.com.
2021-04-26 00:42:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://1004.1004cors.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: 1004.1004cors.com.
2021-04-26 00:42:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://bbd-11.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: bbd-11.com.
2021-04-26 00:42:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://19gum.co.kr> (referer: None)
2021-04-26 00:42:28 [scrapy.core.scraper] ERROR: Spider error processing <GET http://11.xn--he5b93brek8q.com> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:42:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://1004cube.com> (referer: None)
2021-04-26 00:42:28 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://warning.or.kr/i5.html> from <GET http://11toon3.com>
2021-04-26 00:42:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://1004ses.com> (referer: None)
2021-04-26 00:42:28 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://warning.or.kr/i5.html> from <GET http://30.torrent-wal.site>
2021-04-26 00:42:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://gf-119.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: gf-119.com.
2021-04-26 00:42:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://gf-555.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: gf-555.com.
2021-04-26 00:42:28 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://boobyshop.com/shop/> from <GET http://boobyshop.com/shop>
2021-04-26 00:42:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://5rs-a36.com> (referer: None)
2021-04-26 00:42:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://bame.co.kr> (referer: None)
2021-04-26 00:42:28 [scrapy.core.engine] DEBUG: Crawled (409) <GET http://avtv3.top> (referer: None)
2021-04-26 00:42:28 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://ww7.19bam09.com> from <GET http://19bam09.com>
2021-04-26 00:42:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://bbd-777.com> (referer: None)
2021-04-26 00:42:28 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://warning.or.kr/i5.html> from <GET http://5rs-a35.com>
2021-04-26 00:42:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://01.newsdaum.com> (referer: None)
2021-04-26 00:42:28 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://afreecatv.com/> from <GET http://afreecatv.com>
2021-04-26 00:42:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://linetoon10.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: linetoon10.com.
2021-04-26 00:42:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://123-top3.top> (failed 2 times): DNS lookup failed: no results for hostname lookup: 123-top3.top.
2021-04-26 00:42:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://linetoon12.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: linetoon12.com.
2021-04-26 00:42:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://5rs-wc21.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: 5rs-wc21.com.
2021-04-26 00:42:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://77-tws.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: 77-tws.com.
2021-04-26 00:42:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://assktv9.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: assktv9.com.
2021-04-26 00:42:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://bbd-11.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: bbd-11.com.
2021-04-26 00:42:28 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://1004.1004cors.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: 1004.1004cors.com.
2021-04-26 00:42:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://gf-119.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: gf-119.com.
2021-04-26 00:42:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://gf-555.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: gf-555.com.
2021-04-26 00:42:28 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://batoon.xyz/bbs/board.php?bo_table=toon_c&sca=001> from <GET http://batoon.xyz>
2021-04-26 00:42:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://69mart.kr> (referer: None)
2021-04-26 00:42:28 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://warning.or.kr/i1.html> from <GET http://69nuri.shop>
2021-04-26 00:42:28 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://manhwamoa.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: manhwamoa.com.
2021-04-26 00:42:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://1004cube.com> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:42:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://1004ses.com> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:42:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://1004snwo.com> (referer: None)
2021-04-26 00:42:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://bubtv24.com> (failed 1 times): 503 Service Unavailable
2021-04-26 00:42:29 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://avzoa5.top> from <GET http://avzoa.top>
2021-04-26 00:42:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://bamsarang1.me> (referer: None)
2021-04-26 00:42:29 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://warning.or.kr/i5.html> from <GET http://jrjrtv.online>
2021-04-26 00:42:29 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://warning.or.kr/i1.html> from <GET http://free1.live>
2021-04-26 00:42:29 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://warning.or.kr/i1.html> from <GET http://avzoa4.top>
2021-04-26 00:42:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://bbtv24.com/mod> (failed 1 times): 503 Service Unavailable
2021-04-26 00:42:29 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://bubyshop.com/shop/> from <GET http://bubyshop.com/shop>
2021-04-26 00:42:29 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://jikim.tv/> from <GET http://jikimtv.com>
2021-04-26 00:42:29 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://warning.or.kr/i1.html> from <GET http://kavgle.com>
2021-04-26 00:42:29 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.avzoa5.top> from <GET http://avzoa5.top>
2021-04-26 00:42:29 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://warning.or.kr/i2.html> from <GET http://bp-5566.com>
2021-04-26 00:42:29 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://warning.or.kr/i5.html> from <GET http://bosstoon11.com>
2021-04-26 00:42:29 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://jikim.tv/> from <GET http://jikimtv.com/#/sub_cont/live_04.php>
2021-04-26 00:42:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://5rs-a34.com> (referer: None)
2021-04-26 00:42:29 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://warning.or.kr/i1.html> from <GET http://cocojav.com>
2021-04-26 00:42:29 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://kgirlmoa02.com/> from <GET http://kgirlmoa01.com>
2021-04-26 00:42:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://bou-2021.com> (referer: None)
2021-04-26 00:42:29 [scrapy.core.engine] DEBUG: Crawled (403) <GET http://jpdoll.kr> (referer: None)
2021-04-26 00:42:29 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://warning.or.kr/i1.html> from <GET http://kr18.sogirl.co>
2021-04-26 00:42:29 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://warning.or.kr/i5.html> from <GET http://bbant-tv.com>
2021-04-26 00:42:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://fantatv25.com> (failed 1 times): 503 Service Unavailable
2021-04-26 00:42:29 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://gajimall.net/product/list.html?cate_no=236> from <GET http://gajimall.net/product/list.html?cate_no=236>
2021-04-26 00:42:29 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://warning.or.kr/i5.html> from <GET http://88toon.com>
2021-04-26 00:42:29 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://suremen.com/bbs/link.php?bo_table=bo&wr_id=10&no=1> from <GET http://dhlsport.com/?ref=pan>
2021-04-26 00:42:29 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://warning.or.kr/i1.html> from <GET http://ddalbam01.club>
2021-04-26 00:42:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://gmtv3.com> (referer: None)
2021-04-26 00:42:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://goza1.com> (referer: None)
2021-04-26 00:42:29 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://warning.or.kr/i1.html> from <GET http://ace11.live>
2021-04-26 00:42:29 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://warning.or.kr/i1.html> from <GET http://bo-zi18.net>
2021-04-26 00:42:29 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://warning.or.kr/i1.html> from <GET http://assktv8.com>
2021-04-26 00:42:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://69bam3.me> (referer: None)
2021-04-26 00:42:29 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://hdtv.im/> from <GET http://hdtv.im>
2021-04-26 00:42:29 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://hplay.co.kr/> from <GET http://hplay.co.kr>
2021-04-26 00:42:29 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://gongzza.net/> from <GET http://gongzza.net>
2021-04-26 00:42:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://dojun1.com> (referer: None)
2021-04-26 00:42:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://hoxyna5.com> (referer: None)
2021-04-26 00:42:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://linetoon10.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: linetoon10.com.
2021-04-26 00:42:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://linetoon12.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: linetoon12.com.
2021-04-26 00:42:29 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://123-top3.top> (failed 3 times): DNS lookup failed: no results for hostname lookup: 123-top3.top.
2021-04-26 00:42:29 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://5rs-wc21.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: 5rs-wc21.com.
2021-04-26 00:42:29 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://77-tws.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: 77-tws.com.
2021-04-26 00:42:29 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://assktv9.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: assktv9.com.
2021-04-26 00:42:29 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://bbd-11.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: bbd-11.com.
2021-04-26 00:42:29 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://gf-119.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: gf-119.com.
2021-04-26 00:42:29 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://gf-555.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: gf-555.com.
2021-04-26 00:42:29 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <409 http://avtv3.top>: HTTP status code is not handled or not allowed
2021-04-26 00:42:29 [scrapy.core.scraper] ERROR: Error downloading <GET http://1004.1004cors.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: 1004.1004cors.com.
2021-04-26 00:42:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://bbga1.com> (referer: None)
2021-04-26 00:42:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://1004vvt.com> (referer: None)
2021-04-26 00:42:29 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://ww1.hoxyna5.net/?sub1=d6fe0c86-a5dc-11eb-8a37-895940aa5c7d> from <GET http://hoxyna5.net>
2021-04-26 00:42:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://69bam1.me> (referer: None)
2021-04-26 00:42:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://69bam2.me> (referer: None)
2021-04-26 00:42:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://5rs-a36.com> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:42:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://bame.co.kr> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:42:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://bbd-777.com> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:42:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://01.newsdaum.com> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:42:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://batoon.xyz/bbs/board.php?bo_table=toon_c&sca=001> (referer: None)
2021-04-26 00:42:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://ggmee.co.kr> (referer: None)
2021-04-26 00:42:29 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://ktxtorrent19.com/> from <GET http://ktxtorrent19.com>
2021-04-26 00:42:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://mall.thesexymall.co.kr/bbs/login.php> (referer: None)
2021-04-26 00:42:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://hpdv2.top> (referer: None)
2021-04-26 00:42:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://larvatv.com> (referer: None)
2021-04-26 00:42:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://larvatv.com/33> (referer: None)
2021-04-26 00:42:29 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://warning.or.kr/i5.html> from <GET http://manapang2.com>
2021-04-26 00:42:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://manhwamoa.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: manhwamoa.com.
2021-04-26 00:42:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://mcd-11.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: mcd-11.com.
2021-04-26 00:42:29 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://linetoon10.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: linetoon10.com.
2021-04-26 00:42:29 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://linetoon12.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: linetoon12.com.
2021-04-26 00:42:29 [scrapy.core.scraper] ERROR: Error downloading <GET http://hol-100.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1445, in _inlineCallbacks
    result = current_context.run(g.send, result)
StopIteration: <302 http://hol-100.com>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1445, in _inlineCallbacks
    result = current_context.run(g.send, result)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 55, in process_response
    response = yield deferred_from_coro(method(request=request, response=response, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\downloadermiddlewares\redirect.py", line 86, in process_response
    redirected = self._redirect_request_using_get(request, redirected_url)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\downloadermiddlewares\redirect.py", line 50, in _redirect_request_using_get
    redirected = request.replace(url=redirect_url, method='GET', body='')
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\http\request\__init__.py", line 109, in replace
    return cls(*args, **kwargs)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\http\request\__init__.py", line 25, in __init__
    self._set_url(url)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\http\request\__init__.py", line 73, in _set_url
    raise ValueError(f'Missing scheme in request url: {self._url}')
ValueError: Missing scheme in request url: c:/inetpub/custerr/ko-KR/500-19.htm
2021-04-26 00:42:29 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 http://jpdoll.kr>: HTTP status code is not handled or not allowed
2021-04-26 00:42:29 [scrapy.core.scraper] ERROR: Error downloading <GET http://123-top3.top>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: 123-top3.top.
2021-04-26 00:42:29 [scrapy.core.scraper] ERROR: Error downloading <GET http://assktv9.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: assktv9.com.
2021-04-26 00:42:29 [scrapy.core.scraper] ERROR: Error downloading <GET http://77-tws.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: 77-tws.com.
2021-04-26 00:42:29 [scrapy.core.scraper] ERROR: Error downloading <GET http://5rs-wc21.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: 5rs-wc21.com.
2021-04-26 00:42:29 [scrapy.core.scraper] ERROR: Error downloading <GET http://bbd-11.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: bbd-11.com.
2021-04-26 00:42:29 [scrapy.core.scraper] ERROR: Error downloading <GET http://gf-119.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: gf-119.com.
2021-04-26 00:42:29 [scrapy.core.scraper] ERROR: Error downloading <GET http://gf-555.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: gf-555.com.
2021-04-26 00:42:29 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://bubtv24.com> (failed 2 times): 503 Service Unavailable
2021-04-26 00:42:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://cvmp01.site> (referer: None)
2021-04-26 00:42:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://fr-71.com> (referer: None)
2021-04-26 00:42:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://11toon2.com> (referer: None)
2021-04-26 00:42:29 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://aone18.com> from <GET http://aone-45.com>
2021-04-26 00:42:29 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://warning.or.kr/002448570246/i5.html> from <GET http://warning.or.kr/i5.html>
2021-04-26 00:42:29 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://warning.or.kr/002448570246/i5.html> from <GET http://warning.or.kr/i5.html>
2021-04-26 00:42:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://1004snwo.com> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:42:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://bamsarang1.me> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:42:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://5rs-a34.com> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:42:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://gmtv3.com> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:42:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://goza1.com> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:42:29 [scrapy.core.scraper] ERROR: Spider error processing <GET http://69bam3.me> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:42:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://hoxyna5.com> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:42:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://dojun1.com> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:42:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://bbga1.com> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:42:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://69bam1.me> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:42:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://69bam2.me> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:42:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://itoons01.com> (referer: None)
2021-04-26 00:42:30 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://bou-3690.com/> from <GET http://bq-22.com>
2021-04-26 00:42:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://longlongtv.net> (referer: None)
2021-04-26 00:42:30 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://www.avzoa5.top> from <GET http://avzoa5.top>
2021-04-26 00:42:30 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://warning.or.kr/002448570246/i1.html> from <GET http://warning.or.kr/i1.html>
2021-04-26 00:42:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://majortoto.site> (referer: None)
2021-04-26 00:42:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://bettv7.com> (referer: None)
2021-04-26 00:42:30 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://warning.or.kr/002448570246/i5.html> from <GET http://warning.or.kr/i5.html>
2021-04-26 00:42:30 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://frz11.com/> from <GET http://frz-24.com>
2021-04-26 00:42:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://hoxyna6.net> (referer: None)
2021-04-26 00:42:30 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://newkey1212.com/> from <GET http://kring24.com>
2021-04-26 00:42:30 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://bo-zi20.net/bbs/board.php?bo_table=main> from <GET http://bo-zi20.net>
2021-04-26 00:42:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://mcd-79.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: mcd-79.com.
2021-04-26 00:42:30 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://mcd-11.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: mcd-11.com.
2021-04-26 00:42:30 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://manhwamoa.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: manhwamoa.com.
2021-04-26 00:42:30 [scrapy.core.scraper] ERROR: Error downloading <GET http://linetoon12.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: linetoon12.com.
2021-04-26 00:42:30 [scrapy.core.scraper] ERROR: Error downloading <GET http://linetoon10.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: linetoon10.com.
2021-04-26 00:42:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://11toon6.com> (referer: None)
2021-04-26 00:42:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://batoon.xyz/bbs/board.php?bo_table=toon_c&sca=001> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:42:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://ggmee.co.kr> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:42:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://mall.thesexymall.co.kr/bbs/login.php> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:42:30 [scrapy.core.scraper] ERROR: Spider error processing <GET http://hpdv2.top> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:42:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://cvmp01.site> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:42:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://fr-71.com> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:42:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://11toon2.com> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:42:31 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://warning.or.kr/002448570246/i1.html> from <GET http://warning.or.kr/i1.html>
2021-04-26 00:42:31 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://warning.or.kr/002448570246/i1.html> from <GET http://warning.or.kr/i1.html>
2021-04-26 00:42:31 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://bubtv24.com> (failed 3 times): 503 Service Unavailable
2021-04-26 00:42:31 [scrapy.core.engine] DEBUG: Crawled (503) <GET http://bubtv24.com> (referer: None)
2021-04-26 00:42:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://bbtv24.com/mod> (failed 2 times): 503 Service Unavailable
2021-04-26 00:42:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://kgirlmoa02.com> (referer: None)
2021-04-26 00:42:31 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://warning.or.kr/002448570246/i1.html> from <GET http://warning.or.kr/i1.html>
2021-04-26 00:42:31 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://warning.or.kr/002448570246/i5.html> from <GET http://warning.or.kr/i5.html>
2021-04-26 00:42:31 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://warning.or.kr/002448570246/i1.html> from <GET http://warning.or.kr/i1.html>
2021-04-26 00:42:31 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://warning.or.kr/002448570246/i1.html> from <GET http://warning.or.kr/i1.html>
2021-04-26 00:42:31 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://warning.or.kr/002448570246/i5.html> from <GET http://warning.or.kr/i5.html>
2021-04-26 00:42:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://marlboro3.live> (referer: None)
2021-04-26 00:42:31 [scrapy.core.engine] DEBUG: Crawled (999) <GET http://manstv.co.kr> (referer: None)
2021-04-26 00:42:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://fantatv25.com> (failed 2 times): 503 Service Unavailable
2021-04-26 00:42:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://boobyshop.com/shop/> (referer: None)
2021-04-26 00:42:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://zzolboo68.com/> (referer: None)
2021-04-26 00:42:31 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://warning.or.kr/002448570246/i1.html> from <GET http://warning.or.kr/i1.html>
2021-04-26 00:42:31 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://warning.or.kr/002448570246/i1.html> from <GET http://warning.or.kr/i1.html>
2021-04-26 00:42:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://ww7.19bam09.com> (referer: None)
2021-04-26 00:42:31 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://warning.or.kr/002448570246/i1.html> from <GET http://warning.or.kr/i1.html>
2021-04-26 00:42:31 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://warning.or.kr/002448570246/i5.html> from <GET http://warning.or.kr/i5.html>
2021-04-26 00:42:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://avkim1.com> (referer: None)
2021-04-26 00:42:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://ddukcafe.com> (referer: None)
2021-04-26 00:42:31 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://warning.or.kr/002448570246/i2.html> from <GET http://warning.or.kr/i2.html>
2021-04-26 00:42:31 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://warning.or.kr/002448570246/i5.html> from <GET http://warning.or.kr/i5.html>
2021-04-26 00:42:31 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://warning.or.kr/002448570246/i1.html> from <GET http://warning.or.kr/i1.html>
2021-04-26 00:42:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://bo-zi20.net/bbs/board.php?bo_table=main> (referer: None)
2021-04-26 00:42:31 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://mcd-79.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: mcd-79.com.
2021-04-26 00:42:31 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://mcd-11.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: mcd-11.com.
2021-04-26 00:42:31 [scrapy.core.scraper] ERROR: Error downloading <GET http://manhwamoa.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: manhwamoa.com.
2021-04-26 00:42:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://afreecatv.com/> (referer: None)
2021-04-26 00:42:31 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://mcd-79.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: mcd-79.com.
2021-04-26 00:42:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://itoons01.com> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:42:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://longlongtv.net> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:42:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://majortoto.site> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:42:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://bettv7.com> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:42:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://hoxyna6.net> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:42:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://11toon6.com> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:42:31 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET http://www630.shjbksk.co.kr/?todo=bZf4FLRd&sign=7l6MkqzkV5XUzCMJDlTUWXmRMX9w&call=CwVHJTVg7E2ek1rb9QJx4jsKw3&pac=9ec3b66b4b96a5c8663febd8fa9194a9&timeq=6yciIQd> from <GET http://me2.do/5UZBbwhO>
2021-04-26 00:42:31 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://tv14.gongzza.net/> from <GET https://gongzza.net/>
2021-04-26 00:42:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://bubyshop.com/shop/> (referer: None)
2021-04-26 00:42:31 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://warning.or.kr/002448570246/i5.html> from <GET http://warning.or.kr/i5.html>
2021-04-26 00:42:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://aone18.com> (referer: None)
2021-04-26 00:42:31 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <503 http://bubtv24.com>: HTTP status code is not handled or not allowed
2021-04-26 00:42:31 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <999 http://manstv.co.kr>: HTTP status code is not handled or not allowed
2021-04-26 00:42:31 [scrapy.core.scraper] ERROR: Error downloading <GET http://mcd-11.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: mcd-11.com.
2021-04-26 00:42:31 [scrapy.core.scraper] ERROR: Error downloading <GET http://mcd-79.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: mcd-79.com.
2021-04-26 00:42:31 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://warning.or.kr/i5.html> from <GET http://warning.or.kr/002448570246/i5.html>
2021-04-26 00:42:31 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://warning.or.kr/i5.html> from <GET http://warning.or.kr/002448570246/i5.html>
2021-04-26 00:42:31 [scrapy.core.engine] DEBUG: Crawled (403) <GET https://gajimall.net/product/list.html?cate_no=236> (referer: None)
2021-04-26 00:42:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://kgirlmoa02.com> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:42:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://marlboro3.live> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:42:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://boobyshop.com/shop/> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:42:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://zzolboo68.com/> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:42:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://avkim1.com> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:42:32 [scrapy.core.scraper] ERROR: Spider error processing <GET http://ddukcafe.com> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:42:32 [scrapy.core.scraper] ERROR: Spider error processing <GET http://bo-zi20.net/bbs/board.php?bo_table=main> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:42:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://afreecatv.com/> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:42:32 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://dhl1004.com/> from <GET https://suremen.com/bbs/link.php?bo_table=bo&wr_id=10&no=1>
2021-04-26 00:42:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://jikim.tv> (referer: None)
2021-04-26 00:42:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://ming-ky.net> (referer: None)
2021-04-26 00:42:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://hdtv.im/> (referer: None)
2021-04-26 00:42:32 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://warning.or.kr/i5.html> from <GET http://warning.or.kr/002448570246/i5.html>
2021-04-26 00:42:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://jikim.tv/> (referer: None)
2021-04-26 00:42:32 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://warning.or.kr/i1.html> from <GET http://warning.or.kr/002448570246/i1.html>
2021-04-26 00:42:32 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://ww16.menz04.com/?sub1=20210426-0142-303f-b35c-01f995395e2f> from <GET http://menz04.com>
2021-04-26 00:42:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://messi-tv.com> (referer: None)
2021-04-26 00:42:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://hplay.co.kr/> (referer: None)
2021-04-26 00:42:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://frz11.com/> (referer: None)
2021-04-26 00:42:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://jikim.tv/> (referer: None)
2021-04-26 00:42:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://ktxtorrent19.com/> (referer: None)
2021-04-26 00:42:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://bou-3690.com/> (referer: None)
2021-04-26 00:42:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://ww1.hoxyna5.net/?sub1=d6fe0c86-a5dc-11eb-8a37-895940aa5c7d> (referer: None)
2021-04-26 00:42:32 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 https://gajimall.net/product/list.html?cate_no=236>: HTTP status code is not handled or not allowed
2021-04-26 00:42:32 [scrapy.core.scraper] ERROR: Spider error processing <GET http://aone18.com> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:42:32 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://warning.or.kr/i1.html> from <GET http://warning.or.kr/002448570246/i1.html>
2021-04-26 00:42:32 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://warning.or.kr/i5.html> from <GET http://warning.or.kr/002448570246/i5.html>
2021-04-26 00:42:32 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://warning.or.kr/i5.html> from <GET http://warning.or.kr/002448570246/i5.html>
2021-04-26 00:42:32 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://warning.or.kr/i1.html> from <GET http://warning.or.kr/002448570246/i1.html>
2021-04-26 00:42:32 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://fantatv25.com> (failed 3 times): 503 Service Unavailable
2021-04-26 00:42:32 [scrapy.core.engine] DEBUG: Crawled (503) <GET http://fantatv25.com> (referer: None)
2021-04-26 00:42:32 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://warning.or.kr/i1.html> from <GET http://warning.or.kr/002448570246/i1.html>
2021-04-26 00:42:32 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://warning.or.kr/i5.html> from <GET http://warning.or.kr/002448570246/i5.html>
2021-04-26 00:42:32 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://warning.or.kr/i1.html> from <GET http://warning.or.kr/002448570246/i1.html>
2021-04-26 00:42:32 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://warning.or.kr/i1.html> from <GET http://warning.or.kr/002448570246/i1.html>
2021-04-26 00:42:32 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://warning.or.kr/i5.html> from <GET http://warning.or.kr/002448570246/i5.html>
2021-04-26 00:42:32 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://warning.or.kr/i2.html> from <GET http://warning.or.kr/002448570246/i2.html>
2021-04-26 00:42:32 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://warning.or.kr/i1.html> from <GET http://warning.or.kr/002448570246/i1.html>
2021-04-26 00:42:32 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://warning.or.kr/i1.html> from <GET http://warning.or.kr/002448570246/i1.html>
2021-04-26 00:42:32 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://bbtv24.com/mod> (failed 3 times): 503 Service Unavailable
2021-04-26 00:42:32 [scrapy.core.engine] DEBUG: Crawled (503) <GET http://bbtv24.com/mod> (referer: None)
2021-04-26 00:42:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://newkey1212.com/> (failed 1 times): 503 Service Unavailable
2021-04-26 00:42:32 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://warning.or.kr/i1.html> from <GET http://warning.or.kr/002448570246/i1.html>
2021-04-26 00:42:32 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://warning.or.kr/i1.html> from <GET http://warning.or.kr/002448570246/i1.html>
2021-04-26 00:42:32 [scrapy.core.scraper] ERROR: Spider error processing <GET http://jikim.tv> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:42:32 [scrapy.core.scraper] ERROR: Spider error processing <GET http://ming-ky.net> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:42:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://hdtv.im/> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:42:32 [scrapy.core.scraper] ERROR: Spider error processing <GET http://messi-tv.com> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:42:32 [scrapy.core.scraper] ERROR: Spider error processing <GET http://frz11.com/> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:42:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://ktxtorrent19.com/> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:42:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://ww1.hoxyna5.net/?sub1=d6fe0c86-a5dc-11eb-8a37-895940aa5c7d> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:42:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://moatv01.com> (referer: None)
2021-04-26 00:42:33 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://warning.or.kr/i5.html> from <GET http://warning.or.kr/002448570246/i5.html>
2021-04-26 00:42:33 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://ming-ky.net/bbs/board.php?bo_table=main> (referer: None)
2021-04-26 00:42:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://warning.or.kr/i5.html> (referer: None)
2021-04-26 00:42:33 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://mobozi01.me/> from <GET http://mobozi01.me>
2021-04-26 00:42:33 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www630.shjbksk.co.kr/complete.php> from <GET http://www630.shjbksk.co.kr/?todo=bZf4FLRd&sign=7l6MkqzkV5XUzCMJDlTUWXmRMX9w&call=CwVHJTVg7E2ek1rb9QJx4jsKw3&pac=9ec3b66b4b96a5c8663febd8fa9194a9&timeq=6yciIQd>
2021-04-26 00:42:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://kgirlmoa02.com/> (referer: None)
2021-04-26 00:42:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://warning.or.kr/i5.html> (referer: None)
2021-04-26 00:42:33 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <503 http://fantatv25.com>: HTTP status code is not handled or not allowed
2021-04-26 00:42:33 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <503 http://bbtv24.com/mod>: HTTP status code is not handled or not allowed
2021-04-26 00:42:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://warning.or.kr/i5.html> (referer: None)
2021-04-26 00:42:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://warning.or.kr/i1.html> (referer: None)
2021-04-26 00:42:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://warning.or.kr/i5.html> (referer: None)
2021-04-26 00:42:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://warning.or.kr/i1.html> (referer: None)
2021-04-26 00:42:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://warning.or.kr/i1.html> (referer: None)
2021-04-26 00:42:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://warning.or.kr/i1.html> (referer: None)
2021-04-26 00:42:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://warning.or.kr/i5.html> (referer: None)
2021-04-26 00:42:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://warning.or.kr/i1.html> (referer: None)
2021-04-26 00:42:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://warning.or.kr/i1.html> (referer: None)
2021-04-26 00:42:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://warning.or.kr/i1.html> (referer: None)
2021-04-26 00:42:33 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.pandalive.co.kr/evt/tanos&1&ltn&N> from <GET http://www630.shjbksk.co.kr/complete.php>
2021-04-26 00:42:33 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://ming-ky.net/bbs/board.php?bo_table=main>: HTTP status code is not handled or not allowed
2021-04-26 00:42:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://nb-rd.com> (referer: None)
2021-04-26 00:42:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://moatv01.com> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:42:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://warning.or.kr/i5.html> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:42:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://goodlivetv.com> (referer: None)
2021-04-26 00:42:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://tv14.gongzza.net/> (referer: None)
2021-04-26 00:42:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://ww16.menz04.com/?sub1=20210426-0142-303f-b35c-01f995395e2f> (referer: None)
2021-04-26 00:42:34 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://ming-ky1.net/bbs/board.php?bo_table=main> from <GET http://ming-ky1.net>
2021-04-26 00:42:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://pingko2.link> (failed 1 times): DNS lookup failed: no results for hostname lookup: pingko2.link.
2021-04-26 00:42:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://pit-01.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: pit-01.com.
2021-04-26 00:42:35 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2021-04-26 00:42:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://redton50.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: redton50.com.
2021-04-26 00:42:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://redton52.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: redton52.com.
2021-04-26 00:42:35 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://redton52.com/> (failed 1 times): DNS lookup failed: no results for hostname lookup: redton52.com.
2021-04-26 00:42:35 [scrapy.core.engine] INFO: Closing spider (shutdown)
2021-04-26 00:42:36 [scrapy.crawler] INFO: Received SIGINT twice, forcing unclean shutdown
2021-04-26 00:42:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://nb-rd.com> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:42:37 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://warning.or.kr/i2.html> from <GET http://mst-888.com>
2021-04-26 00:42:37 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://namedtoon58.com> from <GET http://namedtoon57.com>
2021-04-26 00:42:37 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://namedtoon58.com> from <GET http://namedtoon57.com/index/index2>
2021-04-26 00:42:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://mst-777.com> (failed 1 times): 503 Service Unavailable
2021-04-26 00:42:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.avzoa5.top> (referer: None)
2021-04-26 00:42:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://namedtoon58.com> (referer: None)
2021-04-26 00:42:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://dhl1004.com/> (referer: None)
2021-04-26 00:42:37 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://warning.or.kr/i5.html> from <GET http://namedtoon51.com>
2021-04-26 00:42:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://nb-fo.com> (referer: None)
2021-04-26 00:42:37 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://warning.or.kr/i5.html> from <GET http://namedtoon52.com>
2021-04-26 00:42:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://ming-ky1.net/bbs/board.php?bo_table=main> (referer: None)
2021-04-26 00:42:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://pingko2.link> (failed 2 times): DNS lookup failed: no results for hostname lookup: pingko2.link.
2021-04-26 00:42:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://pit-01.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: pit-01.com.
2021-04-26 00:42:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://goodlivetv.com> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:42:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://tv14.gongzza.net/> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:42:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://ww16.menz04.com/?sub1=20210426-0142-303f-b35c-01f995395e2f> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:42:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://onair.kbs.co.kr/index.html?sname=onair&stype=live&ch_code=11&ch_type=globalList> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-04-26 00:42:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://oname.kr> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-04-26 00:42:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://onair.imbc.com/?chid=2> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-04-26 00:42:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://red-bam.com> (failed 1 times): An error occurred while connecting: [Failure instance: Traceback (failure with no frames): <class 'twisted.internet.error.ConnectionLost'>: Connection to the other side was lost in a non-clean fashion: Connection lost.
].
2021-04-26 00:42:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://partner.rosetv.co.kr/ln/link.php?ad=58UI7S00244324YC05247574YPK92E> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-04-26 00:42:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://opgram23.com/?utm_source=podo&utm_medium=podo&utm_campaign=podo> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-04-26 00:42:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://qoqtv.com> (failed 1 times): An error occurred while connecting: [Failure instance: Traceback (failure with no frames): <class 'twisted.internet.error.ConnectionLost'>: Connection to the other side was lost in a non-clean fashion: Connection lost.
].
2021-04-26 00:42:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://redton54.com/> (failed 1 times): An error occurred while connecting: [Failure instance: Traceback (failure with no frames): <class 'twisted.internet.error.ConnectionLost'>: Connection to the other side was lost in a non-clean fashion: Connection lost.
].
2021-04-26 00:42:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://mobozi01.me/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-04-26 00:42:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://onair.kbs.co.kr/index.html?sname=onair&stype=live&ch_code=12&ch_type=globalList> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-04-26 00:42:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://play.sbs.co.kr/onair/pc/index.html?div=pc_onair&Channel=sbssports> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-04-26 00:42:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://play.sbs.co.kr/onair/pc/index.html?div=pc_onair> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-04-26 00:42:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://pororotv.com/mod> (failed 1 times): An error occurred while connecting: [Failure instance: Traceback (failure with no frames): <class 'twisted.internet.error.ConnectionLost'>: Connection to the other side was lost in a non-clean fashion: Connection lost.
].
2021-04-26 00:42:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://nb-vf.com> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-04-26 00:42:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://warning.or.kr/i1.html> (failed 1 times): An error occurred while connecting: [Failure instance: Traceback (failure with no frames): <class 'twisted.internet.error.ConnectionLost'>: Connection to the other side was lost in a non-clean fashion: Connection lost.
].
2021-04-26 00:42:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://redton51.com> (failed 1 times): An error occurred while connecting: [Failure instance: Traceback (failure with no frames): <class 'twisted.internet.error.ConnectionLost'>: Connection to the other side was lost in a non-clean fashion: Connection lost.
].
2021-04-26 00:42:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://nene365.com> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-04-26 00:42:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://onair.imbc.com/?chid=4> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-04-26 00:42:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://opbro1.com?utm_source=podo&utm_medium=podo&utm_campaign=podo> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-04-26 00:42:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://newbam21.com> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-04-26 00:42:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://koggiri.tv> (failed 1 times): An error occurred while connecting: [Failure instance: Traceback (failure with no frames): <class 'twisted.internet.error.ConnectionLost'>: Connection to the other side was lost in a non-clean fashion: Connection lost.
].
2021-04-26 00:42:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www.pandalive.co.kr/evt/tanos&1&ltn&N> (failed 1 times): An error occurred while connecting: [Failure instance: Traceback (failure with no frames): <class 'twisted.internet.error.ConnectionLost'>: Connection to the other side was lost in a non-clean fashion: Connection lost.
].
2021-04-26 00:42:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://onair.imbc.com/?chid=3> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-04-26 00:42:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://nene25.com> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-04-26 00:42:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://nb-we.com> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-04-26 00:42:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://onair.kbs.co.kr/index.html?sname=onair&stype=live&ch_code=N91&ch_type=globalList> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-04-26 00:42:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://redking.top> (failed 1 times): An error occurred while connecting: [Failure instance: Traceback (failure with no frames): <class 'twisted.internet.error.ConnectionLost'>: Connection to the other side was lost in a non-clean fashion: Connection lost.
].
2021-04-26 00:42:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://redton54.com> (failed 1 times): An error occurred while connecting: [Failure instance: Traceback (failure with no frames): <class 'twisted.internet.error.ConnectionLost'>: Connection to the other side was lost in a non-clean fashion: Connection lost.
].
2021-04-26 00:42:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://opgram22.com/?utm_source=podo&utm_medium=podo&utm_campaign=podo> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-04-26 00:42:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://redton49.com> (failed 1 times): An error occurred while connecting: [Failure instance: Traceback (failure with no frames): <class 'twisted.internet.error.ConnectionLost'>: Connection to the other side was lost in a non-clean fashion: Connection lost.
].
2021-04-26 00:42:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://sbs18.net> (failed 1 times): An error occurred while connecting: [Failure instance: Traceback (failure with no frames): <class 'twisted.internet.error.ConnectionLost'>: Connection to the other side was lost in a non-clean fashion: Connection lost.
].
2021-04-26 00:42:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://redton53.com/> (failed 1 times): An error occurred while connecting: [Failure instance: Traceback (failure with no frames): <class 'twisted.internet.error.ConnectionLost'>: Connection to the other side was lost in a non-clean fashion: Connection lost.
].
2021-04-26 00:42:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://opgram24.com/?utm_source=podo&utm_medium=podo&utm_campaign=podo> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-04-26 00:42:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://money-tv.com> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-04-26 00:42:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://warning.or.kr/i1.html> (failed 1 times): An error occurred while connecting: [Failure instance: Traceback (failure with no frames): <class 'twisted.internet.error.ConnectionLost'>: Connection to the other side was lost in a non-clean fashion: Connection lost.
].
2021-04-26 00:42:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://redton53.com> (failed 1 times): An error occurred while connecting: [Failure instance: Traceback (failure with no frames): <class 'twisted.internet.error.ConnectionLost'>: Connection to the other side was lost in a non-clean fashion: Connection lost.
].
2021-04-26 00:42:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://onair.imbc.com/?chid=1> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-04-26 00:42:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://bk99-99.com> (failed 1 times): An error occurred while connecting: [Failure instance: Traceback (failure with no frames): <class 'twisted.internet.error.ConnectionLost'>: Connection to the other side was lost in a non-clean fashion: Connection lost.
].
2021-04-26 00:42:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://refice.kr> (failed 1 times): An error occurred while connecting: [Failure instance: Traceback (failure with no frames): <class 'twisted.internet.error.ConnectionLost'>: Connection to the other side was lost in a non-clean fashion: Connection lost.
].
2021-04-26 00:42:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://warning.or.kr/i5.html> (failed 1 times): An error occurred while connecting: [Failure instance: Traceback (failure with no frames): <class 'twisted.internet.error.ConnectionLost'>: Connection to the other side was lost in a non-clean fashion: Connection lost.
].
2021-04-26 00:42:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://newkey1212.com/> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-04-26 00:42:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://ppowertv.com> (failed 1 times): An error occurred while connecting: [Failure instance: Traceback (failure with no frames): <class 'twisted.internet.error.ConnectionLost'>: Connection to the other side was lost in a non-clean fashion: Connection lost.
].
2021-04-26 00:42:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://onair.imbc.com> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-04-26 00:42:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://safe.ggongt.com> (failed 1 times): An error occurred while connecting: [Failure instance: Traceback (failure with no frames): <class 'twisted.internet.error.ConnectionLost'>: Connection to the other side was lost in a non-clean fashion: Connection lost.
].
2021-04-26 00:42:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://warning.or.kr/i5.html> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-04-26 00:42:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://red1.red-bam.com> (failed 1 times): An error occurred while connecting: [Failure instance: Traceback (failure with no frames): <class 'twisted.internet.error.ConnectionLost'>: Connection to the other side was lost in a non-clean fashion: Connection lost.
].
2021-04-26 00:42:37 [scrapy.core.downloader.handlers.http11] WARNING: Got data loss in http://goltv.co.kr. If you want to process broken responses set the setting DOWNLOAD_FAIL_ON_DATALOSS = False -- This message won't be shown in further requests
2021-04-26 00:42:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://goltv.co.kr> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>, <twisted.python.failure.Failure twisted.web.http._DataLoss: Chunked decoder in 'CHUNK_LENGTH' state, still expecting more data to get to 'FINISHED' state.>]
2021-04-26 00:42:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://warning.or.kr/i2.html> (failed 1 times): An error occurred while connecting: [Failure instance: Traceback (failure with no frames): <class 'twisted.internet.error.ConnectionLost'>: Connection to the other side was lost in a non-clean fashion: Connection lost.
].
2021-04-26 00:42:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://warning.or.kr/i1.html> (failed 1 times): An error occurred while connecting: [Failure instance: Traceback (failure with no frames): <class 'twisted.internet.error.ConnectionLost'>: Connection to the other side was lost in a non-clean fashion: Connection lost.
].
2021-04-26 00:42:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://refpa.top/L?tag=d_805161m_14237c__[]general[]_d42020_l37766_banner&site=805161&ad=14237&r=ko/bonus/rules> (failed 1 times): An error occurred while connecting: [Failure instance: Traceback (failure with no frames): <class 'twisted.internet.error.ConnectionLost'>: Connection to the other side was lost in a non-clean fashion: Connection lost.
].
2021-04-26 00:42:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://noonbbog.com> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-04-26 00:42:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.avzoa5.top> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-04-26 00:42:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://qootoon.com/27429f6c> (failed 1 times): An error occurred while connecting: [Failure instance: Traceback (failure with no frames): <class 'twisted.internet.error.ConnectionLost'>: Connection to the other side was lost in a non-clean fashion: Connection lost.
].
2021-04-26 00:43:19 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: crawler)
2021-04-26 00:43:19 [scrapy.utils.log] INFO: Versions: lxml 4.6.3.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.2.0, Python 3.7.8 (tags/v3.7.8:4b47a5b6ba, Jun 28 2020, 08:53:46) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 20.0.1 (OpenSSL 1.1.1k  25 Mar 2021), cryptography 3.4.7, Platform Windows-10-10.0.19041-SP0
2021-04-26 00:43:19 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2021-04-26 00:43:19 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'crawler',
 'CONCURRENT_REQUESTS': 100,
 'DEPTH_PRIORITY': 1,
 'LOG_FILE': 'log3.txt',
 'NEWSPIDER_MODULE': 'crawler.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SCHEDULER_DISK_QUEUE': 'scrapy.squeues.PickleFifoDiskQueue',
 'SCHEDULER_MEMORY_QUEUE': 'scrapy.squeues.FifoMemoryQueue',
 'SPIDER_MODULES': ['crawler.spiders']}
2021-04-26 00:43:19 [scrapy.extensions.telnet] INFO: Telnet Password: d14784b8feba88bd
2021-04-26 00:43:20 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2021-04-26 00:43:20 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2021-04-26 00:43:20 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2021-04-26 00:43:20 [scrapy.middleware] INFO: Enabled item pipelines:
['crawler.pipelines.CrawlerPipeline']
2021-04-26 00:43:20 [scrapy.core.engine] INFO: Spider opened
2021-04-26 00:43:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2021-04-26 00:43:20 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://01.newsdaum.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: 01.newsdaum.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://1004.1004cors.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: 1004.1004cors.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://1004cube.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: 1004cube.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://1004hks.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: 1004hks.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://1004ses.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: 1004ses.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://1004snwo.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: 1004snwo.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://1004svs.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: 1004svs.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://01.newsdaum.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: 01.newsdaum.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://1004.1004cors.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: 1004.1004cors.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://1004vvt.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: 1004vvt.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://1004cube.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: 1004cube.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://1004hks.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: 1004hks.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://1004ses.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: 1004ses.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://1004snwo.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: 1004snwo.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://1004x.1004tsts.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: 1004x.1004tsts.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://1004svs.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: 1004svs.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://01.newsdaum.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: 01.newsdaum.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://1004.1004cors.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: 1004.1004cors.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://11.xn--he5b93brek8q.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: 11.xn--he5b93brek8q.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://1004vvt.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: 1004vvt.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://1004x.1004tsts.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: 1004x.1004tsts.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://1004cube.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: 1004cube.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://1004hks.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: 1004hks.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://1004ses.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: 1004ses.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://1004snwo.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: 1004snwo.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://11toon2.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: 11toon2.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://11.xn--he5b93brek8q.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: 11.xn--he5b93brek8q.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://1004svs.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: 1004svs.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://11toon3.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: 11toon3.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://1004vvt.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: 1004vvt.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://1004x.1004tsts.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: 1004x.1004tsts.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://11toon6.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: 11toon6.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://11toon2.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: 11toon2.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://11.xn--he5b93brek8q.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: 11.xn--he5b93brek8q.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://123-top3.top> (failed 1 times): DNS lookup failed: no results for hostname lookup: 123-top3.top.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://11toon3.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: 11toon3.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://1234.1004vvt.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: 1234.1004vvt.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://11toon6.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: 11toon6.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://11toon2.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: 11toon2.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://19bam09.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: 19bam09.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://123-top3.top> (failed 2 times): DNS lookup failed: no results for hostname lookup: 123-top3.top.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://11toon3.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: 11toon3.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://19gum.co.kr> (failed 1 times): DNS lookup failed: no results for hostname lookup: 19gum.co.kr.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://1234.1004vvt.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: 1234.1004vvt.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://11toon6.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: 11toon6.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://22kbs.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: 22kbs.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://19bam09.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: 19bam09.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://123-top3.top> (failed 3 times): DNS lookup failed: no results for hostname lookup: 123-top3.top.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://30.torrent-wal.site> (failed 1 times): DNS lookup failed: no results for hostname lookup: 30.torrent-wal.site.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://19gum.co.kr> (failed 2 times): DNS lookup failed: no results for hostname lookup: 19gum.co.kr.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://1234.1004vvt.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: 1234.1004vvt.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://5rs-a34.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: 5rs-a34.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://22kbs.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: 22kbs.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://19bam09.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: 19bam09.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://5rs-a35.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: 5rs-a35.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://30.torrent-wal.site> (failed 2 times): DNS lookup failed: no results for hostname lookup: 30.torrent-wal.site.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://19gum.co.kr> (failed 3 times): DNS lookup failed: no results for hostname lookup: 19gum.co.kr.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://5rs-a36.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: 5rs-a36.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://5rs-a34.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: 5rs-a34.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://22kbs.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: 22kbs.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://5rs-wc21.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: 5rs-wc21.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://5rs-a35.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: 5rs-a35.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://30.torrent-wal.site> (failed 3 times): DNS lookup failed: no results for hostname lookup: 30.torrent-wal.site.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://69bam1.me> (failed 1 times): DNS lookup failed: no results for hostname lookup: 69bam1.me.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://5rs-a36.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: 5rs-a36.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://5rs-a34.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: 5rs-a34.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://69bam2.me> (failed 1 times): DNS lookup failed: no results for hostname lookup: 69bam2.me.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://5rs-wc21.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: 5rs-wc21.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://5rs-a35.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: 5rs-a35.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://69bam3.me> (failed 1 times): DNS lookup failed: no results for hostname lookup: 69bam3.me.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://69bam1.me> (failed 2 times): DNS lookup failed: no results for hostname lookup: 69bam1.me.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://5rs-a36.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: 5rs-a36.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://69mart.kr> (failed 1 times): DNS lookup failed: no results for hostname lookup: 69mart.kr.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://69bam2.me> (failed 2 times): DNS lookup failed: no results for hostname lookup: 69bam2.me.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://5rs-wc21.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: 5rs-wc21.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://69nuri.shop> (failed 1 times): DNS lookup failed: no results for hostname lookup: 69nuri.shop.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://69bam3.me> (failed 2 times): DNS lookup failed: no results for hostname lookup: 69bam3.me.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://69bam1.me> (failed 3 times): DNS lookup failed: no results for hostname lookup: 69bam1.me.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://77-tws.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: 77-tws.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://69mart.kr> (failed 2 times): DNS lookup failed: no results for hostname lookup: 69mart.kr.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://69bam2.me> (failed 3 times): DNS lookup failed: no results for hostname lookup: 69bam2.me.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://88toon.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: 88toon.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://69nuri.shop> (failed 2 times): DNS lookup failed: no results for hostname lookup: 69nuri.shop.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://69bam3.me> (failed 3 times): DNS lookup failed: no results for hostname lookup: 69bam3.me.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://ace11.live> (failed 1 times): DNS lookup failed: no results for hostname lookup: ace11.live.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://77-tws.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: 77-tws.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://69mart.kr> (failed 3 times): DNS lookup failed: no results for hostname lookup: 69mart.kr.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://afreecatv.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: afreecatv.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://88toon.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: 88toon.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://69nuri.shop> (failed 3 times): DNS lookup failed: no results for hostname lookup: 69nuri.shop.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://aone-45.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: aone-45.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://ace11.live> (failed 2 times): DNS lookup failed: no results for hostname lookup: ace11.live.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://77-tws.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: 77-tws.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://assktv8.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: assktv8.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://afreecatv.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: afreecatv.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://88toon.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: 88toon.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://assktv9.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: assktv9.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://aone-45.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: aone-45.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://ace11.live> (failed 3 times): DNS lookup failed: no results for hostname lookup: ace11.live.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://avkim1.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: avkim1.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://assktv8.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: assktv8.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://afreecatv.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: afreecatv.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://avtv3.top> (failed 1 times): DNS lookup failed: no results for hostname lookup: avtv3.top.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://assktv9.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: assktv9.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://aone-45.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: aone-45.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://avzoa.top> (failed 1 times): DNS lookup failed: no results for hostname lookup: avzoa.top.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://avkim1.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: avkim1.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://assktv8.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: assktv8.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://avzoa4.top> (failed 1 times): DNS lookup failed: no results for hostname lookup: avzoa4.top.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://avtv3.top> (failed 2 times): DNS lookup failed: no results for hostname lookup: avtv3.top.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://assktv9.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: assktv9.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://avzoa5.top> (failed 1 times): DNS lookup failed: no results for hostname lookup: avzoa5.top.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://avzoa.top> (failed 2 times): DNS lookup failed: no results for hostname lookup: avzoa.top.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://avkim1.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: avkim1.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://bame.co.kr> (failed 1 times): DNS lookup failed: no results for hostname lookup: bame.co.kr.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://avzoa4.top> (failed 2 times): DNS lookup failed: no results for hostname lookup: avzoa4.top.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://avtv3.top> (failed 3 times): DNS lookup failed: no results for hostname lookup: avtv3.top.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://bamsarang1.me> (failed 1 times): DNS lookup failed: no results for hostname lookup: bamsarang1.me.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://avzoa5.top> (failed 2 times): DNS lookup failed: no results for hostname lookup: avzoa5.top.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://avzoa.top> (failed 3 times): DNS lookup failed: no results for hostname lookup: avzoa.top.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://batoon.xyz> (failed 1 times): DNS lookup failed: no results for hostname lookup: batoon.xyz.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://bame.co.kr> (failed 2 times): DNS lookup failed: no results for hostname lookup: bame.co.kr.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://avzoa4.top> (failed 3 times): DNS lookup failed: no results for hostname lookup: avzoa4.top.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://bbant-tv.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: bbant-tv.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://bamsarang1.me> (failed 2 times): DNS lookup failed: no results for hostname lookup: bamsarang1.me.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://avzoa5.top> (failed 3 times): DNS lookup failed: no results for hostname lookup: avzoa5.top.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://bbd-11.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: bbd-11.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://batoon.xyz> (failed 2 times): DNS lookup failed: no results for hostname lookup: batoon.xyz.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://bame.co.kr> (failed 3 times): DNS lookup failed: no results for hostname lookup: bame.co.kr.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://bbd-777.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: bbd-777.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://bbant-tv.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: bbant-tv.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://bamsarang1.me> (failed 3 times): DNS lookup failed: no results for hostname lookup: bamsarang1.me.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://bbga1.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: bbga1.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://bbd-11.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: bbd-11.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://bbd-777.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: bbd-777.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://batoon.xyz> (failed 3 times): DNS lookup failed: no results for hostname lookup: batoon.xyz.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://bbtv24.com/mod> (failed 1 times): DNS lookup failed: no results for hostname lookup: bbtv24.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://bbant-tv.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: bbant-tv.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://bbga1.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: bbga1.com.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://01.newsdaum.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: 01.newsdaum.com.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://1004.1004cors.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: 1004.1004cors.com.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://1004cube.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: 1004cube.com.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://1004hks.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: 1004hks.com.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://1004ses.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: 1004ses.com.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://1004snwo.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: 1004snwo.com.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://1004svs.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: 1004svs.com.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://1004vvt.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: 1004vvt.com.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://1004x.1004tsts.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: 1004x.1004tsts.com.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://11.xn--he5b93brek8q.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: 11.xn--he5b93brek8q.com.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://11toon2.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: 11toon2.com.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://11toon3.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: 11toon3.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://bbd-11.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: bbd-11.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://bbd-777.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: bbd-777.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://bettv7.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: bettv7.com.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://11toon6.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: 11toon6.com.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://123-top3.top>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: 123-top3.top.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://1234.1004vvt.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: 1234.1004vvt.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://bk99-99.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: bk99-99.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://bbtv24.com/mod> (failed 2 times): DNS lookup failed: no results for hostname lookup: bbtv24.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://bbga1.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: bbga1.com.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://19bam09.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: 19bam09.com.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://19gum.co.kr>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: 19gum.co.kr.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://bo-zi18.net> (failed 1 times): DNS lookup failed: no results for hostname lookup: bo-zi18.net.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://bettv7.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: bettv7.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://bo-zi20.net> (failed 1 times): DNS lookup failed: no results for hostname lookup: bo-zi20.net.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://bk99-99.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: bk99-99.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://bbtv24.com/mod> (failed 3 times): DNS lookup failed: no results for hostname lookup: bbtv24.com.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://22kbs.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: 22kbs.com.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://30.torrent-wal.site>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: 30.torrent-wal.site.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://boobyshop.com/shop> (failed 1 times): DNS lookup failed: no results for hostname lookup: boobyshop.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://bo-zi18.net> (failed 2 times): DNS lookup failed: no results for hostname lookup: bo-zi18.net.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://bo-zi20.net> (failed 2 times): DNS lookup failed: no results for hostname lookup: bo-zi20.net.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://5rs-a34.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: 5rs-a34.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://bettv7.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: bettv7.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://bk99-99.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: bk99-99.com.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://5rs-a35.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: 5rs-a35.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://bosstoon11.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: bosstoon11.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://boobyshop.com/shop> (failed 2 times): DNS lookup failed: no results for hostname lookup: boobyshop.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://bo-zi18.net> (failed 3 times): DNS lookup failed: no results for hostname lookup: bo-zi18.net.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://bo-zi20.net> (failed 3 times): DNS lookup failed: no results for hostname lookup: bo-zi20.net.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://5rs-a36.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: 5rs-a36.com.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://5rs-wc21.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: 5rs-wc21.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://bou-2021.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: bou-2021.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://bp-5566.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: bp-5566.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://bosstoon11.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: bosstoon11.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://boobyshop.com/shop> (failed 3 times): DNS lookup failed: no results for hostname lookup: boobyshop.com.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://69bam1.me>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: 69bam1.me.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://bq-22.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: bq-22.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://bou-2021.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: bou-2021.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://bp-5566.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: bp-5566.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://bosstoon11.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: bosstoon11.com.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://69bam2.me>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: 69bam2.me.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://69bam3.me>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: 69bam3.me.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://bubtv24.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: bubtv24.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://bq-22.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: bq-22.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://bou-2021.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: bou-2021.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://bp-5566.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: bp-5566.com.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://69mart.kr>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: 69mart.kr.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://69nuri.shop>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: 69nuri.shop.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://bubyshop.com/shop> (failed 1 times): DNS lookup failed: no results for hostname lookup: bubyshop.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://cocojav.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: cocojav.com.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://77-tws.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: 77-tws.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://bubtv24.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: bubtv24.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://bq-22.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: bq-22.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://cvmp01.site> (failed 1 times): DNS lookup failed: no results for hostname lookup: cvmp01.site.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://bubyshop.com/shop> (failed 2 times): DNS lookup failed: no results for hostname lookup: bubyshop.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://cocojav.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: cocojav.com.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://88toon.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: 88toon.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://ddalbam01.club> (failed 1 times): DNS lookup failed: no results for hostname lookup: ddalbam01.club.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://cvmp01.site> (failed 2 times): DNS lookup failed: no results for hostname lookup: cvmp01.site.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://bubtv24.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: bubtv24.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://bubyshop.com/shop> (failed 3 times): DNS lookup failed: no results for hostname lookup: bubyshop.com.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://ace11.live>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: ace11.live.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://afreecatv.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: afreecatv.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://cocojav.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: cocojav.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://ddukcafe.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: ddukcafe.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://ddalbam01.club> (failed 2 times): DNS lookup failed: no results for hostname lookup: ddalbam01.club.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://cvmp01.site> (failed 3 times): DNS lookup failed: no results for hostname lookup: cvmp01.site.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://aone-45.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: aone-45.com.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://assktv8.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: assktv8.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://dhlsport.com/?ref=pan> (failed 1 times): DNS lookup failed: no results for hostname lookup: dhlsport.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://ddukcafe.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: ddukcafe.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://ddalbam01.club> (failed 3 times): DNS lookup failed: no results for hostname lookup: ddalbam01.club.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://assktv9.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: assktv9.com.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://avkim1.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: avkim1.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://dojun1.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: dojun1.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://dhlsport.com/?ref=pan> (failed 2 times): DNS lookup failed: no results for hostname lookup: dhlsport.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://ddukcafe.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: ddukcafe.com.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://avtv3.top>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: avtv3.top.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://fantatv25.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: fantatv25.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://dojun1.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: dojun1.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://dhlsport.com/?ref=pan> (failed 3 times): DNS lookup failed: no results for hostname lookup: dhlsport.com.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://avzoa.top>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: avzoa.top.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://fr-71.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: fr-71.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://fantatv25.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: fantatv25.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://dojun1.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: dojun1.com.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://avzoa4.top>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: avzoa4.top.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://avzoa5.top>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: avzoa5.top.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://free1.live> (failed 1 times): DNS lookup failed: no results for hostname lookup: free1.live.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://fr-71.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: fr-71.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://fantatv25.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: fantatv25.com.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://bame.co.kr>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: bame.co.kr.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://frz-24.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: frz-24.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://gajimall.net/product/list.html?cate_no=236> (failed 1 times): DNS lookup failed: no results for hostname lookup: gajimall.net.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://free1.live> (failed 2 times): DNS lookup failed: no results for hostname lookup: free1.live.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://fr-71.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: fr-71.com.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://bamsarang1.me>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: bamsarang1.me.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://gf-119.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: gf-119.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://frz-24.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: frz-24.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://gajimall.net/product/list.html?cate_no=236> (failed 2 times): DNS lookup failed: no results for hostname lookup: gajimall.net.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://free1.live> (failed 3 times): DNS lookup failed: no results for hostname lookup: free1.live.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://batoon.xyz>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: batoon.xyz.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://gf-555.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: gf-555.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://gf-119.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: gf-119.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://frz-24.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: frz-24.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://gajimall.net/product/list.html?cate_no=236> (failed 3 times): DNS lookup failed: no results for hostname lookup: gajimall.net.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://ggmee.co.kr> (failed 1 times): DNS lookup failed: no results for hostname lookup: ggmee.co.kr.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://gf-555.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: gf-555.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://gf-119.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: gf-119.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://gmtv3.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: gmtv3.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://goltv.co.kr> (failed 1 times): DNS lookup failed: no results for hostname lookup: goltv.co.kr.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://ggmee.co.kr> (failed 2 times): DNS lookup failed: no results for hostname lookup: ggmee.co.kr.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://gongzza.net> (failed 1 times): DNS lookup failed: no results for hostname lookup: gongzza.net.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://gmtv3.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: gmtv3.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://gf-555.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: gf-555.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://goodlivetv.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: goodlivetv.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://goltv.co.kr> (failed 2 times): DNS lookup failed: no results for hostname lookup: goltv.co.kr.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://ggmee.co.kr> (failed 3 times): DNS lookup failed: no results for hostname lookup: ggmee.co.kr.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://goza1.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: goza1.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://gongzza.net> (failed 2 times): DNS lookup failed: no results for hostname lookup: gongzza.net.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://gmtv3.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: gmtv3.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://hdtv.im> (failed 1 times): DNS lookup failed: no results for hostname lookup: hdtv.im.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://goodlivetv.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: goodlivetv.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://goltv.co.kr> (failed 3 times): DNS lookup failed: no results for hostname lookup: goltv.co.kr.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://hol-100.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: hol-100.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://goza1.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: goza1.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://gongzza.net> (failed 3 times): DNS lookup failed: no results for hostname lookup: gongzza.net.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://bbant-tv.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: bbant-tv.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://hoxyna5.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: hoxyna5.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://hdtv.im> (failed 2 times): DNS lookup failed: no results for hostname lookup: hdtv.im.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://goodlivetv.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: goodlivetv.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://hoxyna5.net> (failed 1 times): DNS lookup failed: no results for hostname lookup: hoxyna5.net.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://hol-100.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: hol-100.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://goza1.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: goza1.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://hoxyna6.net> (failed 1 times): DNS lookup failed: no results for hostname lookup: hoxyna6.net.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://hoxyna5.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: hoxyna5.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://hdtv.im> (failed 3 times): DNS lookup failed: no results for hostname lookup: hdtv.im.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://bbd-11.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: bbd-11.com.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://bbd-777.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: bbd-777.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://hpdv2.top> (failed 1 times): DNS lookup failed: no results for hostname lookup: hpdv2.top.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://hoxyna5.net> (failed 2 times): DNS lookup failed: no results for hostname lookup: hoxyna5.net.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://hol-100.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: hol-100.com.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://bbga1.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: bbga1.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://hplay.co.kr> (failed 1 times): DNS lookup failed: no results for hostname lookup: hplay.co.kr.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://hoxyna6.net> (failed 2 times): DNS lookup failed: no results for hostname lookup: hoxyna6.net.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://hoxyna5.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: hoxyna5.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://itoons01.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: itoons01.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://hpdv2.top> (failed 2 times): DNS lookup failed: no results for hostname lookup: hpdv2.top.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://hoxyna5.net> (failed 3 times): DNS lookup failed: no results for hostname lookup: hoxyna5.net.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://bbtv24.com/mod>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: bbtv24.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://jikim.tv> (failed 1 times): DNS lookup failed: no results for hostname lookup: jikim.tv.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://hplay.co.kr> (failed 2 times): DNS lookup failed: no results for hostname lookup: hplay.co.kr.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://itoons01.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: itoons01.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://hoxyna6.net> (failed 3 times): DNS lookup failed: no results for hostname lookup: hoxyna6.net.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://hpdv2.top> (failed 3 times): DNS lookup failed: no results for hostname lookup: hpdv2.top.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://bettv7.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: bettv7.com.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://bk99-99.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: bk99-99.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://jikimtv.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: jikimtv.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://jikim.tv> (failed 2 times): DNS lookup failed: no results for hostname lookup: jikim.tv.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://hplay.co.kr> (failed 3 times): DNS lookup failed: no results for hostname lookup: hplay.co.kr.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://itoons01.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: itoons01.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://jikimtv.com/#/sub_cont/live_04.php> (failed 1 times): DNS lookup failed: no results for hostname lookup: jikimtv.com.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://bo-zi18.net>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: bo-zi18.net.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://bo-zi20.net>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: bo-zi20.net.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://jpdoll.kr> (failed 1 times): DNS lookup failed: no results for hostname lookup: jpdoll.kr.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://jikimtv.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: jikimtv.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://jikimtv.com/#/sub_cont/live_04.php> (failed 2 times): DNS lookup failed: no results for hostname lookup: jikimtv.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://jikim.tv> (failed 3 times): DNS lookup failed: no results for hostname lookup: jikim.tv.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://boobyshop.com/shop>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: boobyshop.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://jrjrtv.online> (failed 1 times): DNS lookup failed: no results for hostname lookup: jrjrtv.online.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://jpdoll.kr> (failed 2 times): DNS lookup failed: no results for hostname lookup: jpdoll.kr.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://jikimtv.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: jikimtv.com.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://bosstoon11.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: bosstoon11.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://jikimtv.com/#/sub_cont/live_04.php> (failed 3 times): DNS lookup failed: no results for hostname lookup: jikimtv.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://kavgle.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: kavgle.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://jrjrtv.online> (failed 2 times): DNS lookup failed: no results for hostname lookup: jrjrtv.online.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://jpdoll.kr> (failed 3 times): DNS lookup failed: no results for hostname lookup: jpdoll.kr.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://kgirlmoa01.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: kgirlmoa01.com.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://bou-2021.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: bou-2021.com.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://bp-5566.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: bp-5566.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://kavgle.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: kavgle.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://jrjrtv.online> (failed 3 times): DNS lookup failed: no results for hostname lookup: jrjrtv.online.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://kgirlmoa02.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: kgirlmoa02.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://koggiri.tv> (failed 1 times): DNS lookup failed: no results for hostname lookup: koggiri.tv.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://kgirlmoa01.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: kgirlmoa01.com.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://bq-22.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: bq-22.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://kr18.sogirl.co> (failed 1 times): DNS lookup failed: no results for hostname lookup: kr18.sogirl.co.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://kgirlmoa02.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: kgirlmoa02.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://kavgle.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: kavgle.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://kgirlmoa01.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: kgirlmoa01.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://koggiri.tv> (failed 2 times): DNS lookup failed: no results for hostname lookup: koggiri.tv.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://bubtv24.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: bubtv24.com.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://bubyshop.com/shop>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: bubyshop.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://kring24.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: kring24.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://kr18.sogirl.co> (failed 2 times): DNS lookup failed: no results for hostname lookup: kr18.sogirl.co.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://kgirlmoa02.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: kgirlmoa02.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://ktxtorrent19.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: ktxtorrent19.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://koggiri.tv> (failed 3 times): DNS lookup failed: no results for hostname lookup: koggiri.tv.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://cocojav.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: cocojav.com.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://cvmp01.site>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: cvmp01.site.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://larvatv.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: larvatv.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://kring24.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: kring24.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://kr18.sogirl.co> (failed 3 times): DNS lookup failed: no results for hostname lookup: kr18.sogirl.co.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://larvatv.com/33> (failed 1 times): DNS lookup failed: no results for hostname lookup: larvatv.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://ktxtorrent19.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: ktxtorrent19.com.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://ddalbam01.club>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: ddalbam01.club.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://linetoon10.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: linetoon10.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://larvatv.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: larvatv.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://larvatv.com/33> (failed 2 times): DNS lookup failed: no results for hostname lookup: larvatv.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://kring24.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: kring24.com.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://ddukcafe.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: ddukcafe.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://ktxtorrent19.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: ktxtorrent19.com.
2021-04-26 00:43:20 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://linetoon12.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: linetoon12.com.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://dhlsport.com/?ref=pan>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: dhlsport.com.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://dojun1.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: dojun1.com.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://fantatv25.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: fantatv25.com.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://fr-71.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: fr-71.com.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://free1.live>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: free1.live.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://frz-24.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: frz-24.com.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://gajimall.net/product/list.html?cate_no=236>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: gajimall.net.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://gf-119.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: gf-119.com.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://gf-555.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: gf-555.com.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://ggmee.co.kr>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: ggmee.co.kr.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://gmtv3.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: gmtv3.com.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://goltv.co.kr>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: goltv.co.kr.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://gongzza.net>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: gongzza.net.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://goodlivetv.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: goodlivetv.com.
2021-04-26 00:43:20 [scrapy.core.scraper] ERROR: Error downloading <GET http://goza1.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: goza1.com.
2021-04-26 00:43:21 [scrapy.core.scraper] ERROR: Error downloading <GET http://hdtv.im>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: hdtv.im.
2021-04-26 00:43:21 [scrapy.core.scraper] ERROR: Error downloading <GET http://hol-100.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: hol-100.com.
2021-04-26 00:43:21 [scrapy.core.scraper] ERROR: Error downloading <GET http://hoxyna5.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: hoxyna5.com.
2021-04-26 00:43:21 [scrapy.core.scraper] ERROR: Error downloading <GET http://hoxyna5.net>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: hoxyna5.net.
2021-04-26 00:43:21 [scrapy.core.scraper] ERROR: Error downloading <GET http://hoxyna6.net>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: hoxyna6.net.
2021-04-26 00:43:21 [scrapy.core.scraper] ERROR: Error downloading <GET http://hpdv2.top>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: hpdv2.top.
2021-04-26 00:43:21 [scrapy.core.scraper] ERROR: Error downloading <GET http://hplay.co.kr>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: hplay.co.kr.
2021-04-26 00:43:21 [scrapy.core.scraper] ERROR: Error downloading <GET http://itoons01.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: itoons01.com.
2021-04-26 00:43:21 [scrapy.core.scraper] ERROR: Error downloading <GET http://jikim.tv>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: jikim.tv.
2021-04-26 00:43:21 [scrapy.core.scraper] ERROR: Error downloading <GET http://jikimtv.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: jikimtv.com.
2021-04-26 00:43:21 [scrapy.core.scraper] ERROR: Error downloading <GET http://jikimtv.com/#/sub_cont/live_04.php>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: jikimtv.com.
2021-04-26 00:43:21 [scrapy.core.scraper] ERROR: Error downloading <GET http://jpdoll.kr>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: jpdoll.kr.
2021-04-26 00:43:21 [scrapy.core.scraper] ERROR: Error downloading <GET http://jrjrtv.online>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: jrjrtv.online.
2021-04-26 00:43:21 [scrapy.core.scraper] ERROR: Error downloading <GET http://kgirlmoa01.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: kgirlmoa01.com.
2021-04-26 00:43:21 [scrapy.core.scraper] ERROR: Error downloading <GET http://kavgle.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: kavgle.com.
2021-04-26 00:43:21 [scrapy.core.scraper] ERROR: Error downloading <GET http://kgirlmoa02.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: kgirlmoa02.com.
2021-04-26 00:43:21 [scrapy.core.scraper] ERROR: Error downloading <GET http://koggiri.tv>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: koggiri.tv.
2021-04-26 00:43:21 [scrapy.core.scraper] ERROR: Error downloading <GET http://kr18.sogirl.co>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: kr18.sogirl.co.
2021-04-26 00:43:21 [scrapy.core.scraper] ERROR: Error downloading <GET http://kring24.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: kring24.com.
2021-04-26 00:43:21 [scrapy.core.scraper] ERROR: Error downloading <GET http://ktxtorrent19.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: ktxtorrent19.com.
2021-04-26 00:43:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://larvatv.com> (referer: None)
2021-04-26 00:43:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://longlongtv.net> (referer: None)
2021-04-26 00:43:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://larvatv.com> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:43:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://linetoon10.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: linetoon10.com.
2021-04-26 00:43:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://linetoon12.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: linetoon12.com.
2021-04-26 00:43:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://manhwamoa.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: manhwamoa.com.
2021-04-26 00:43:59 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://mcd-11.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: mcd-11.com.
2021-04-26 00:44:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://longlongtv.net> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:44:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://mcd-79.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: mcd-79.com.
2021-04-26 00:44:14 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET http://mana.forward-links2.com/> from <GET http://manapang2.com>
2021-04-26 00:44:14 [scrapy.core.engine] DEBUG: Crawled (403) <GET http://manstv.co.kr> (referer: None)
2021-04-26 00:44:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://marlboro3.live> (referer: None)
2021-04-26 00:44:14 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 http://manstv.co.kr>: HTTP status code is not handled or not allowed
2021-04-26 00:44:16 [scrapy.core.scraper] ERROR: Spider error processing <GET http://marlboro3.live> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:44:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://mall.thesexymall.co.kr/bbs/login.php> (referer: None)
2021-04-26 00:44:16 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://ming-ky1.net/bbs/board.php?bo_table=main> from <GET http://ming-ky1.net>
2021-04-26 00:44:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://majortoto.site> (referer: None)
2021-04-26 00:44:16 [scrapy.core.engine] DEBUG: Crawled (404) <GET http://ming-ky.net/bbs/board.php?bo_table=main> (referer: None)
2021-04-26 00:44:16 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (301) to <GET https://mobozi01.me/> from <GET http://mobozi01.me>
2021-04-26 00:44:16 [scrapy.core.engine] DEBUG: Crawled (403) <GET http://messi-tv.com> (referer: None)
2021-04-26 00:44:16 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (307) to <GET http://www630.shjbksk.co.kr/?todo=bZf4FLRd&sign=7l6MkqzkV5XUzCMJDlTUWXmRMX9w&call=CwVHJTVg7E2ek1rb9QJx4jsKw3&pac=9ec3b66b4b96a5c8663febd8fa9194a9&timeq=6yciIQd> from <GET http://me2.do/5UZBbwhO>
2021-04-26 00:44:16 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://ww16.menz04.com/?sub1=20210426-0144-13d0-bf0b-7a0a16a1dcc1> from <GET http://menz04.com>
2021-04-26 00:44:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://ming-ky.net> (referer: None)
2021-04-26 00:44:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://larvatv.com/33> (referer: None)
2021-04-26 00:44:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://moatv01.com> (referer: None)
2021-04-26 00:44:18 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 http://ming-ky.net/bbs/board.php?bo_table=main>: HTTP status code is not handled or not allowed
2021-04-26 00:44:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://ming-ky1.net/bbs/board.php?bo_table=main> (referer: None)
2021-04-26 00:44:18 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 http://messi-tv.com>: HTTP status code is not handled or not allowed
2021-04-26 00:44:32 [scrapy.core.scraper] ERROR: Spider error processing <GET http://majortoto.site> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:44:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://namedtoon57.com/index/index2> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-04-26 00:44:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://namedtoon52.com> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-04-26 00:44:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://mobozi01.me/> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-04-26 00:44:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://namedtoon58.com> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-04-26 00:44:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://namedtoon57.com> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-04-26 00:44:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://mst-888.com> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-04-26 00:44:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://namedtoon51.com> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-04-26 00:44:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://nb-fo.com> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-04-26 00:44:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://mst-777.com> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-04-26 00:44:32 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://pingko2.link> (failed 1 times): DNS lookup failed: no results for hostname lookup: pingko2.link.
2021-04-26 00:44:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://ming-ky.net> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:44:54 [scrapy.core.scraper] ERROR: Spider error processing <GET http://moatv01.com> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:44:54 [scrapy.extensions.logstats] INFO: Crawled 12 pages (at 12 pages/min), scraped 0 items (at 0 items/min)
2021-04-26 00:44:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://pit-01.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: pit-01.com.
2021-04-26 00:44:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://play.sbs.co.kr/onair/pc/index.html?div=pc_onair&Channel=sbssports> (failed 1 times): DNS lookup failed: no results for hostname lookup: play.sbs.co.kr.
2021-04-26 00:44:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://play.sbs.co.kr/onair/pc/index.html?div=pc_onair> (failed 1 times): DNS lookup failed: no results for hostname lookup: play.sbs.co.kr.
2021-04-26 00:44:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://pororotv.com/mod> (failed 1 times): DNS lookup failed: no results for hostname lookup: pororotv.com.
2021-04-26 00:44:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://qootoon.com/27429f6c> (failed 1 times): DNS lookup failed: no results for hostname lookup: qootoon.com.
2021-04-26 00:44:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://ppowertv.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: ppowertv.com.
2021-04-26 00:44:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://red1.red-bam.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: red1.red-bam.com.
2021-04-26 00:44:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://red-bam.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: red-bam.com.
2021-04-26 00:44:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://qoqtv.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: qoqtv.com.
2021-04-26 00:44:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://redking.top> (failed 1 times): DNS lookup failed: no results for hostname lookup: redking.top.
2021-04-26 00:44:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://redton50.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: redton50.com.
2021-04-26 00:44:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://redton49.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: redton49.com.
2021-04-26 00:44:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://redton52.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: redton52.com.
2021-04-26 00:44:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://redton51.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: redton51.com.
2021-04-26 00:44:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://redton53.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: redton53.com.
2021-04-26 00:44:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://redton52.com/> (failed 1 times): DNS lookup failed: no results for hostname lookup: redton52.com.
2021-04-26 00:44:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://redton54.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: redton54.com.
2021-04-26 00:44:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://redton53.com/> (failed 1 times): DNS lookup failed: no results for hostname lookup: redton53.com.
2021-04-26 00:44:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://redton54.com/> (failed 1 times): DNS lookup failed: no results for hostname lookup: redton54.com.
2021-04-26 00:44:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://refice.kr> (failed 1 times): DNS lookup failed: no results for hostname lookup: refice.kr.
2021-04-26 00:44:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://refpa.top/L?tag=d_805161m_14237c__[]general[]_d42020_l37766_banner&site=805161&ad=14237&r=ko/bonus/rules> (failed 1 times): DNS lookup failed: no results for hostname lookup: refpa.top.
2021-04-26 00:44:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://safe.ggongt.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: safe.ggongt.com.
2021-04-26 00:44:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://sbtv7.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: sbtv7.com.
2021-04-26 00:44:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://sbs18.net> (failed 1 times): DNS lookup failed: no results for hostname lookup: sbs18.net.
2021-04-26 00:44:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://sinsa.net> (failed 1 times): DNS lookup failed: no results for hostname lookup: sinsa.net.
2021-04-26 00:44:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://sexbam11.me> (failed 1 times): DNS lookup failed: no results for hostname lookup: sexbam11.me.
2021-04-26 00:44:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://secrettoy.co.kr/intro.asp> (failed 1 times): DNS lookup failed: no results for hostname lookup: secrettoy.co.kr.
2021-04-26 00:44:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://smdozen.top> (failed 1 times): DNS lookup failed: no results for hostname lookup: smdozen.top.
2021-04-26 00:44:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://smtv-on.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: smtv-on.com.
2021-04-26 00:44:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://sns-a7.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: sns-a7.com.
2021-04-26 00:44:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://soul-88.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: soul-88.com.
2021-04-26 00:44:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://sns-x5.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: sns-x5.com.
2021-04-26 00:44:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://sns-x3.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: sns-x3.com.
2021-04-26 00:44:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://ssongssong22.net> (failed 1 times): DNS lookup failed: no results for hostname lookup: ssongssong22.net.
2021-04-26 00:44:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://sxxk6.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: sxxk6.com.
2021-04-26 00:44:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://ssongssong23.net> (failed 1 times): DNS lookup failed: no results for hostname lookup: ssongssong23.net.
2021-04-26 00:44:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://tazotv15.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: tazotv15.com.
2021-04-26 00:44:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://tmttv24.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: tmttv24.com.
2021-04-26 00:44:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://toon123.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: toon123.com.
2021-04-26 00:44:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://tomatomv.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: tomatomv.com.
2021-04-26 00:44:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://toptoy.co.kr/shop> (failed 1 times): DNS lookup failed: no results for hostname lookup: toptoy.co.kr.
2021-04-26 00:44:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://toonbook.net> (failed 1 times): DNS lookup failed: no results for hostname lookup: toonbook.net.
2021-04-26 00:44:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://torrentgo28.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: torrentgo28.com.
2021-04-26 00:44:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://torrentsir27.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: torrentsir27.com.
2021-04-26 00:44:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://torrentwon18.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: torrentwon18.com.
2021-04-26 00:44:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://torrentwon19.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: torrentwon19.com.
2021-04-26 00:44:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://toto-mall.com/index.php?mid=livetv> (failed 1 times): DNS lookup failed: no results for hostname lookup: toto-mall.com.
2021-04-26 00:44:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://toto-mall.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: toto-mall.com.
2021-04-26 00:44:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://tsgirl.net> (failed 1 times): DNS lookup failed: no results for hostname lookup: tsgirl.net.
2021-04-26 00:44:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://tsgirl.net/bbs/board.php?bo_table=main> (failed 1 times): DNS lookup failed: no results for hostname lookup: tsgirl.net.
2021-04-26 00:44:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://nb-vf.com> (failed 1 times): 408 Request Time-out
2021-04-26 00:44:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://nb-rd.com> (referer: None)
2021-04-26 00:44:58 [scrapy.core.scraper] ERROR: Spider error processing <GET http://ming-ky1.net/bbs/board.php?bo_table=main> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:44:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://nene365.com> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-04-26 00:44:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://onair.imbc.com/?chid=2> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-04-26 00:44:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://onair.imbc.com/?chid=4> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-04-26 00:44:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://noonbbog.com> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-04-26 00:44:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://onair.imbc.com/?chid=1> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-04-26 00:44:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://nene25.com> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-04-26 00:44:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://onair.imbc.com/?chid=3> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-04-26 00:44:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://newbam21.com> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-04-26 00:44:58 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://onair.imbc.com> (failed 1 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-04-26 00:45:34 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2021-04-26 00:45:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://nb-rd.com> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:45:34 [scrapy.core.engine] DEBUG: Crawled (403) <GET http://opgram23.com/?utm_source=podo&utm_medium=podo&utm_campaign=podo> (referer: None)
2021-04-26 00:45:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://nb-we.com> (referer: None)
2021-04-26 00:45:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://money-tv.com> (referer: None)
2021-04-26 00:45:34 [scrapy.core.engine] DEBUG: Crawled (400) <GET http://opbro1.com?utm_source=podo&utm_medium=podo&utm_campaign=podo> (referer: None)
2021-04-26 00:45:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://onair.kbs.co.kr/index.html?sname=onair&stype=live&ch_code=11&ch_type=globalList> (referer: None)
2021-04-26 00:45:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://onair.kbs.co.kr/index.html?sname=onair&stype=live&ch_code=N91&ch_type=globalList> (referer: None)
2021-04-26 00:45:34 [scrapy.core.engine] DEBUG: Crawled (403) <GET http://oname.kr> (referer: None)
2021-04-26 00:45:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://onair.kbs.co.kr/index.html?sname=onair&stype=live&ch_code=12&ch_type=globalList> (referer: None)
2021-04-26 00:45:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://partner.rosetv.co.kr/ln/link.php?ad=58UI7S00244324YC05247574YPK92E> (referer: None)
2021-04-26 00:45:34 [scrapy.core.engine] DEBUG: Crawled (403) <GET http://opgram22.com/?utm_source=podo&utm_medium=podo&utm_campaign=podo> (referer: None)
2021-04-26 00:45:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://opgram24.com/?utm_source=podo&utm_medium=podo&utm_campaign=podo> (referer: None)
2021-04-26 00:45:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://manhwamoa.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: manhwamoa.com.
2021-04-26 00:45:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://mcd-11.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: mcd-11.com.
2021-04-26 00:45:34 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://linetoon10.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: linetoon10.com.
2021-04-26 00:45:34 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET http://linetoon12.com> (failed 3 times): DNS lookup failed: no results for hostname lookup: linetoon12.com.
2021-04-26 00:45:34 [scrapy.core.engine] INFO: Closing spider (shutdown)
2021-04-26 00:45:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://mcd-79.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: mcd-79.com.
2021-04-26 00:45:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://mana.forward-links2.com/> (failed 1 times): DNS lookup failed: no results for hostname lookup: mana.forward-links2.com.
2021-04-26 00:45:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://tulbo.tv> (failed 1 times): DNS lookup failed: no results for hostname lookup: tulbo.tv.
2021-04-26 00:45:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://tv.hobbang.net> (failed 1 times): DNS lookup failed: no results for hostname lookup: tv.hobbang.net.
2021-04-26 00:45:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://ww16.menz04.com/?sub1=20210426-0144-13d0-bf0b-7a0a16a1dcc1> (failed 1 times): DNS lookup failed: no results for hostname lookup: ww16.menz04.com.
2021-04-26 00:45:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://www630.shjbksk.co.kr/?todo=bZf4FLRd&sign=7l6MkqzkV5XUzCMJDlTUWXmRMX9w&call=CwVHJTVg7E2ek1rb9QJx4jsKw3&pac=9ec3b66b4b96a5c8663febd8fa9194a9&timeq=6yciIQd> (failed 1 times): DNS lookup failed: no results for hostname lookup: www630.shjbksk.co.kr.
2021-04-26 00:45:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://tv2.dasitvlink.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: tv2.dasitvlink.com.
2021-04-26 00:45:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://tv24.co.kr> (failed 1 times): DNS lookup failed: no results for hostname lookup: tv24.co.kr.
2021-04-26 00:45:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://tv3.dasitvlink.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: tv3.dasitvlink.com.
2021-04-26 00:45:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://tvnamu.kr> (failed 1 times): DNS lookup failed: no results for hostname lookup: tvnamu.kr.
2021-04-26 00:45:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://video.meailtv.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: video.meailtv.com.
2021-04-26 00:45:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://uribrotv.com> (failed 1 times): DNS lookup failed: no results for hostname lookup: uribrotv.com.
2021-04-26 00:45:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://viptv365.com/web/inc/main.asp> (failed 1 times): DNS lookup failed: no results for hostname lookup: viptv365.com.
2021-04-26 00:45:34 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 12 pages/min), scraped 0 items (at 0 items/min)
2021-04-26 00:45:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://namedtoon58.com> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-04-26 00:45:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://namedtoon52.com> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-04-26 00:45:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://mst-888.com> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-04-26 00:45:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://mobozi01.me/> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-04-26 00:45:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://namedtoon51.com> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-04-26 00:45:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://namedtoon57.com/index/index2> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-04-26 00:45:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://mst-777.com> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-04-26 00:45:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://namedtoon57.com> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-04-26 00:45:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://nb-fo.com> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.>]
2021-04-26 00:45:34 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://nb-vf.com> (failed 2 times): 408 Request Time-out
2021-04-26 00:45:34 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 http://opgram23.com/?utm_source=podo&utm_medium=podo&utm_campaign=podo>: HTTP status code is not handled or not allowed
2021-04-26 00:45:34 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 http://opbro1.com?utm_source=podo&utm_medium=podo&utm_campaign=podo>: HTTP status code is not handled or not allowed
2021-04-26 00:45:34 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 http://oname.kr>: HTTP status code is not handled or not allowed
2021-04-26 00:45:34 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <403 http://opgram22.com/?utm_source=podo&utm_medium=podo&utm_campaign=podo>: HTTP status code is not handled or not allowed
2021-04-26 00:45:48 [scrapy.crawler] INFO: Received SIGINT twice, forcing unclean shutdown
2021-04-26 00:45:48 [scrapy.core.scraper] ERROR: Spider error processing <GET http://nb-we.com> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:46:12 [scrapy.core.scraper] ERROR: Spider error processing <GET http://money-tv.com> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:46:12 [scrapy.core.scraper] ERROR: Error downloading <GET http://linetoon10.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: linetoon10.com.
2021-04-26 00:46:12 [scrapy.core.scraper] ERROR: Error downloading <GET http://linetoon12.com>
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 1443, in _inlineCallbacks
    result = current_context.run(result.throwExceptionIntoGenerator, g)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\python\failure.py", line 500, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\downloader\middleware.py", line 45, in process_request
    return (yield download_func(request=request, spider=spider))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\defer.py", line 662, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\twisted\internet\endpoints.py", line 1025, in startConnectionAttempts
    "no results for hostname lookup: {}".format(self._hostStr)
twisted.internet.error.DNSLookupError: DNS lookup failed: no results for hostname lookup: linetoon12.com.
2021-04-26 00:46:13 [scrapy.core.scraper] ERROR: Spider error processing <GET http://onair.kbs.co.kr/index.html?sname=onair&stype=live&ch_code=11&ch_type=globalList> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:46:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://partner.rosetv.co.kr/ln/link.php?ad=58UI7S00244324YC05247574YPK92E> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:46:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://pingko2.link> (failed 2 times): DNS lookup failed: no results for hostname lookup: pingko2.link.
2021-04-26 00:46:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://pit-01.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: pit-01.com.
2021-04-26 00:46:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://redton50.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: redton50.com.
2021-04-26 00:46:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://redton52.com> (failed 2 times): DNS lookup failed: no results for hostname lookup: redton52.com.
2021-04-26 00:46:14 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://redton52.com/> (failed 2 times): DNS lookup failed: no results for hostname lookup: redton52.com.
2021-04-26 00:46:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://opgram24.com/?utm_source=podo&utm_medium=podo&utm_campaign=podo> (referer: None)
Traceback (most recent call last):
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 340, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\cyc54\.virtualenvs\crawlproject--dt58ojd\lib\site-packages\scrapy\core\spidermw.py", line 62, in _evaluate_iterable
    for r in iterable:
  File "E:\Project\CrawlProject\crawler\spiders\sites.py", line 135, in parse
    self.log.write(response.url, baseIP)
TypeError: write() takes exactly one argument (2 given)
2021-04-26 00:46:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://noonbbog.com> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-04-26 00:46:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://onair.imbc.com/?chid=2> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-04-26 00:46:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://onair.imbc.com> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-04-26 00:46:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://nene25.com> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-04-26 00:46:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://newbam21.com> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-04-26 00:46:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://onair.imbc.com/?chid=1> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-04-26 00:46:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://nene365.com> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-04-26 00:46:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://onair.imbc.com/?chid=3> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-04-26 00:46:15 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET http://onair.imbc.com/?chid=4> (failed 2 times): [<twisted.python.failure.Failure twisted.internet.error.ConnectionLost: Connection to the other side was lost in a non-clean fashion: Connection lost.>]
2021-04-26 00:46:40 [scrapy.utils.log] INFO: Scrapy 2.4.1 started (bot: crawler)
2021-04-26 00:46:40 [scrapy.utils.log] INFO: Versions: lxml 4.6.3.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.2.0, Python 3.7.8 (tags/v3.7.8:4b47a5b6ba, Jun 28 2020, 08:53:46) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 20.0.1 (OpenSSL 1.1.1k  25 Mar 2021), cryptography 3.4.7, Platform Windows-10-10.0.19041-SP0
2021-04-26 00:46:40 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2021-04-26 00:46:40 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'crawler',
 'CONCURRENT_REQUESTS': 100,
 'DEPTH_PRIORITY': 1,
 'LOG_FILE': 'log3.txt',
 'NEWSPIDER_MODULE': 'crawler.spiders',
 'REACTOR_THREADPOOL_MAXSIZE': 20,
 'SCHEDULER_DISK_QUEUE': 'scrapy.squeues.PickleFifoDiskQueue',
 'SCHEDULER_MEMORY_QUEUE': 'scrapy.squeues.FifoMemoryQueue',
 'SPIDER_MODULES': ['crawler.spiders']}
2021-04-26 00:46:40 [scrapy.extensions.telnet] INFO: Telnet Password: 1de081625cb58959
2021-04-26 00:46:40 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2021-04-26 00:46:40 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2021-04-26 00:46:40 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2021-04-26 00:46:40 [scrapy.middleware] INFO: Enabled item pipelines:
['crawler.pipelines.CrawlerPipeline']
2021-04-26 00:46:40 [scrapy.core.engine] INFO: Spider opened
2021-04-26 00:46:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2021-04-26 00:46:40 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2021-04-26 00:46:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://01.newsdaum.com> (referer: None)
2021-04-26 00:46:55 [google.auth._default] DEBUG: Checking E:\Project\CrawlProject\crawler\googlekey\ardent-strength-309105-f9e6b458ea6a.json for explicit credentials as part of auth process...
2021-04-26 00:46:56 [google.auth.transport.requests] DEBUG: Making request: POST https://oauth2.googleapis.com/token
2021-04-26 00:46:56 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): oauth2.googleapis.com:443
2021-04-26 00:47:21 [urllib3.connectionpool] DEBUG: https://oauth2.googleapis.com:443 "POST /token HTTP/1.1" 200 None
2021-04-26 00:47:36 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2021-04-26 00:47:36 [google.auth._default] DEBUG: Checking E:\Project\CrawlProject\crawler\googlekey\ardent-strength-309105-f9e6b458ea6a.json for explicit credentials as part of auth process...
2021-04-26 00:47:36 [scrapy.crawler] INFO: Received SIGINT twice, forcing unclean shutdown
2021-04-26 00:47:37 [google.auth.transport.requests] DEBUG: Making request: POST https://oauth2.googleapis.com/token
2021-04-26 00:47:37 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): oauth2.googleapis.com:443
